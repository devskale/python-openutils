"""
Core classes for the UniInfer package.
"""
import asyncio
import httpx
from typing import Any, AsyncIterator, Optional
from collections.abc import Iterator


class ChatMessage:
    """
    A message in a chat conversation.

    Attributes:
        role (str): The role of the message sender (user, assistant, system).
        content (str): The content of the message.
        tool_calls (list[dict] | None): Tool calls generated by the model.
        tool_call_id (str | None): ID of the tool call this message responds to.
    """

    def __init__(self, role: str, content: str | list[dict] | None, tool_calls: list[dict] | None = None, tool_call_id: str | None = None):
        self.role = role
        self.content = content
        self.tool_calls = tool_calls
        self.tool_call_id = tool_call_id

    def to_dict(self) -> dict[str, Any]:
        """Convert to a dictionary format suitable for API requests."""
        data = {
            "role": self.role,
            "content": self.content
        }
        if self.tool_calls:
            data["tool_calls"] = self.tool_calls
        if self.tool_call_id:
            data["tool_call_id"] = self.tool_call_id
        return data


class ChatCompletionRequest:
    """
    A request for a chat completion.

    Attributes:
        messages (list[ChatMessage]): The conversation history.
        model (str | None): The model to use for completion.
        temperature (float): Controls randomness in generation.
        max_tokens (int | None): Maximum tokens to generate.
        streaming (bool): Whether to stream the response.
        tools (list[dict] | None): List of tools available to the model.
        tool_choice (Any | None): Tool choice preference.
    """

    def __init__(
        self,
        messages: list[ChatMessage],
        model: str | None = None,
        temperature: float = 1.0,
        max_tokens: int | None = None,
        streaming: bool = False,
        tools: list[dict] | None = None,
        tool_choice: Any | None = None,
        reasoning_effort: str | None = None
    ):
        self.messages = messages
        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.streaming = streaming
        self.tools = tools
        self.tool_choice = tool_choice
        self.reasoning_effort = reasoning_effort


class ChatCompletionResponse:
    """
    A response from a chat completion.

    Attributes:
        message (ChatMessage): The generated message.
        provider (str): The provider that generated the response.
        model (str): The model used for generation.
        usage (dict): Token usage information.
        raw_response (Any): The raw response from the provider.
        finish_reason (str | None): The reason for completion.
        thinking (str | None): Thinking/reasoning content (for thinking models).
    """

    def __init__(
        self,
        message: ChatMessage,
        provider: str,
        model: str,
        usage: dict,
        raw_response: Any,
        finish_reason: str | None = None,
        thinking: str | None = None
    ):
        self.message = message
        self.provider = provider
        self.model = model
        self.usage = usage
        self.raw_response = raw_response
        self.finish_reason = finish_reason
        self.thinking = thinking


class ChatProvider:
    """
    Abstract base class for chat providers.

    All provider implementations must inherit from this class and implement
    the complete and stream_complete methods.
    """

    def __init__(self, api_key: str | None = None, **kwargs):
        """
        Initialize the provider with an API key and optional configuration.

        Args:
            api_key (str | None): The API key for authentication.
            **kwargs: Additional provider-specific configuration parameters.
        """
        self.api_key = api_key
        self._async_client: Optional[httpx.AsyncClient] = None
        # Additional provider-specific configuration can be handled by subclasses

    async def _get_async_client(self) -> httpx.AsyncClient:
        """Get or create the internal httpx.AsyncClient."""
        if self._async_client is None or self._async_client.is_closed:
            self._async_client = httpx.AsyncClient(timeout=60.0)
        return self._async_client

    async def aclose(self):
        """Close the internal httpx.AsyncClient if it exists."""
        if self._async_client and not self._async_client.is_closed:
            await self._async_client.aclose()

    @classmethod
    def list_models(cls, api_key: str | None = None, **kwargs) -> list[str]:
        """
        Standard interface for listing available models.

        Args:
            api_key (str | None): API key if needed for listing models
            **kwargs: Additional provider-specific parameters

        Returns:
            list[str]: List of available model names
        """
        raise NotImplementedError("Providers must implement list_models")

    def complete(
        self,
        request: ChatCompletionRequest,
        **provider_specific_kwargs
    ) -> ChatCompletionResponse:
        """
        Make a chat completion request.
        """
        async def run_and_close():
            try:
                return await self.acomplete(request, **provider_specific_kwargs)
            finally:
                await self.aclose()
        
        return asyncio.run(run_and_close())

    def stream_complete(
        self,
        request: ChatCompletionRequest,
        **provider_specific_kwargs
    ) -> Iterator[ChatCompletionResponse]:
        """
        Stream a chat completion response.
        """
        async_gen = self.astream_complete(request, **provider_specific_kwargs)
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        try:
            while True:
                try:
                    yield loop.run_until_complete(async_gen.__anext__())
                except StopAsyncIteration:
                    break
                except Exception:
                    # Re-raise any other exception after cleanup
                    raise
        finally:
            # Properly close the async generator
            async def cleanup():
                try:
                    await async_gen.aclose()
                except Exception:
                    pass
                try:
                    await self.aclose()
                except Exception:
                    pass
            
            loop.run_until_complete(cleanup())
            loop.run_until_complete(loop.shutdown_asyncgens())
            loop.close()

    async def acomplete(
        self,
        request: ChatCompletionRequest,
        **provider_specific_kwargs
    ) -> ChatCompletionResponse:
        """
        Make an async chat completion request.

        Args:
            request (ChatCompletionRequest): The request to make.
            **provider_specific_kwargs: Additional provider-specific parameters.

        Returns:
            ChatCompletionResponse: The completion response.
        """
        raise NotImplementedError(
            "Providers must implement the acomplete method")

    async def astream_complete(
        self,
        request: ChatCompletionRequest,
        **provider_specific_kwargs
    ) -> AsyncIterator[ChatCompletionResponse]:
        """
        Stream an async chat completion response.

        Args:
            request (ChatCompletionRequest): The request to make.
            **provider_specific_kwargs: Additional provider-specific parameters.

        Returns:
            AsyncIterator[ChatCompletionResponse]: An async iterator of response chunks.
        """
        raise NotImplementedError(
            "Providers must implement the astream_complete method")


class EmbeddingRequest:
    """
    A request for embeddings.

    Attributes:
        input (list[str]): The texts to embed.
        model (str | None): The model to use for embedding.
        encoding_format (str): The format to return the embeddings in.
        dimensions (int | None): The number of dimensions the resulting output embeddings should have.
        user (str | None): A unique identifier representing your end-user.
    """

    def __init__(
        self,
        input: list[str],
        model: str | None = None,
        encoding_format: str = "float",
        dimensions: int | None = None,
        user: str | None = None
    ):
        self.input = input
        self.model = model
        self.encoding_format = encoding_format
        self.dimensions = dimensions
        self.user = user


class EmbeddingResponse:
    """
    A response from an embedding request.

    Attributes:
        object (str): The object type, always "list".
        data (list[dict]): The embedding data.
        model (str): The model used for embedding.
        usage (dict): Token usage information.
        provider (str): The provider that generated the response.
        raw_response (Any): The raw response from the provider.
    """

    def __init__(
        self,
        object: str,
        data: list[dict],
        model: str,
        usage: dict,
        provider: str,
        raw_response: Any
    ):
        self.object = object
        self.data = data
        self.model = model
        self.usage = usage
        self.provider = provider
        self.raw_response = raw_response


class EmbeddingProvider:
    """
    Abstract base class for embedding providers.

    All embedding provider implementations must inherit from this class and implement
    the embed method.
    """

    def __init__(self, api_key: str | None = None, **kwargs):
        """
        Initialize the provider with an API key and optional configuration.

        Args:
            api_key (str | None): The API key for authentication.
            **kwargs: Additional provider-specific configuration parameters.
        """
        self.api_key = api_key
        self._async_client: Optional[httpx.AsyncClient] = None
        # Additional provider-specific configuration can be handled by subclasses

    async def _get_async_client(self) -> httpx.AsyncClient:
        """Get or create the internal httpx.AsyncClient."""
        if self._async_client is None or self._async_client.is_closed:
            self._async_client = httpx.AsyncClient(timeout=60.0)
        return self._async_client

    async def aclose(self):
        """Close the internal httpx.AsyncClient if it exists."""
        if self._async_client and not self._async_client.is_closed:
            await self._async_client.aclose()

    @classmethod
    def list_models(cls, **kwargs) -> list[str]:
        """
        Standard interface for listing available models.

        Args:
            **kwargs: Additional provider-specific parameters

        Returns:
            list[str]: List of available model names
        """
        raise NotImplementedError(
            "Embedding providers must implement list_models")

    def embed(
        self,
        request: EmbeddingRequest,
        **provider_specific_kwargs
    ) -> EmbeddingResponse:
        """
        Make an embedding request.
        """
        async def run_and_close():
            try:
                return await self.aembed(request, **provider_specific_kwargs)
            finally:
                await self.aclose()
        
        return asyncio.run(run_and_close())

    async def aembed(
        self,
        request: EmbeddingRequest,
        **provider_specific_kwargs
    ) -> EmbeddingResponse:
        """
        Make an async embedding request.

        Args:
            request (EmbeddingRequest): The request to make.
            **provider_specific_kwargs: Additional provider-specific parameters.

        Returns:
            EmbeddingResponse: The embedding response.
        """
        raise NotImplementedError(
            "Embedding providers must implement the aembed method")


class TTSRequest:
    """
    A request for text-to-speech generation.

    Attributes:
        input (str): The text to convert to speech.
        model (str | None): The model to use for TTS.
        voice (str | None): The voice to use.
        response_format (str): The audio format (mp3, opus, aac, flac, wav, pcm).
        speed (float): The speed of the generated audio (0.25 to 4.0).
        instructions (str | None): Additional instructions for the TTS model.
    """

    def __init__(
        self,
        input: str,
        model: str | None = None,
        voice: str | None = None,
        response_format: str = "mp3",
        speed: float = 1.0,
        instructions: str | None = None
    ):
        self.input = input
        self.model = model
        self.voice = voice
        self.response_format = response_format
        self.speed = speed
        self.instructions = instructions


class TTSResponse:
    """
    A response from a TTS request.

    Attributes:
        audio_content (bytes): The generated audio content.
        model (str): The model used for generation.
        provider (str): The provider that generated the response.
        content_type (str): The MIME type of the audio content.
        raw_response (Any): The raw response from the provider.
    """

    def __init__(
        self,
        audio_content: bytes,
        model: str,
        provider: str,
        content_type: str = "audio/mpeg",
        raw_response: Any = None
    ):
        self.audio_content = audio_content
        self.model = model
        self.provider = provider
        self.content_type = content_type
        self.raw_response = raw_response


class TTSProvider:
    """
    Abstract base class for TTS providers.

    All TTS provider implementations must inherit from this class and implement
    the generate_speech method.
    """

    def __init__(self, api_key: str | None = None, **kwargs):
        """
        Initialize the provider with an API key and optional configuration.

        Args:
            api_key (str | None): The API key for authentication.
            **kwargs: Additional provider-specific configuration parameters.
        """
        self.api_key = api_key

    @classmethod
    def list_models(cls, api_key: str | None = None, **kwargs) -> list[str]:
        """
        Standard interface for listing available TTS models.

        Args:
            api_key (str | None): API key if needed for listing models
            **kwargs: Additional provider-specific parameters

        Returns:
            list[str]: List of available model names
        """
        return []

    async def _get_async_client(self) -> httpx.AsyncClient:
        """Get or create the internal httpx.AsyncClient."""
        if not hasattr(self, '_async_client') or self._async_client is None or self._async_client.is_closed:
            self._async_client = httpx.AsyncClient(timeout=300.0)
        return self._async_client

    async def aclose(self):
        """Close the internal httpx.AsyncClient if it exists."""
        if hasattr(self, '_async_client') and self._async_client and not self._async_client.is_closed:
            await self._async_client.aclose()

    def generate_speech(
        self,
        request: TTSRequest,
        **provider_specific_kwargs
    ) -> TTSResponse:
        """
        Generate speech from text.
        """
        async def run_and_close():
            try:
                return await self.agenerate_speech(request, **provider_specific_kwargs)
            finally:
                await self.aclose()
        
        return asyncio.run(run_and_close())

    async def agenerate_speech(
        self,
        request: TTSRequest,
        **provider_specific_kwargs
    ) -> TTSResponse:
        """
        Generate speech from text asynchronously.

        Args:
            request (TTSRequest): The request to make.
            **provider_specific_kwargs: Additional provider-specific parameters.

        Returns:
            TTSResponse: The TTS response with audio content.

        Raises:
            Exception: If the request fails.
        """
        raise NotImplementedError(
            "TTS providers must implement the agenerate_speech method")


class STTRequest:
    """
    A request for speech-to-text transcription.

    Attributes:
        file (str | bytes): The audio file path or content to transcribe.
        model (str | None): The model to use for transcription.
        language (str | None): The language of the audio (ISO-639-1 format).
        prompt (str | None): Optional text to guide the model's style.
        response_format (str): The format of the transcript output.
        temperature (float): Sampling temperature (0 to 1).
        timestamp_granularities (list[str] | None): Timestamp granularities.
    """

    def __init__(
        self,
        file: str | bytes,
        model: str | None = None,
        language: str | None = None,
        prompt: str | None = None,
        response_format: str = "json",
        temperature: float = 0.0,
        timestamp_granularities: list[str] | None = None
    ):
        self.file = file
        self.model = model
        self.language = language
        self.prompt = prompt
        self.response_format = response_format
        self.temperature = temperature
        self.timestamp_granularities = timestamp_granularities


class STTResponse:
    """
    A response from an STT request.

    Attributes:
        text (str): The transcribed text.
        model (str): The model used for transcription.
        provider (str): The provider that generated the response.
        language (str | None): Detected or specified language.
        duration (float | None): Duration of the audio in seconds.
        segments (list[dict] | None): Detailed segments with timestamps.
        raw_response (Any): The raw response from the provider.
    """

    def __init__(
        self,
        text: str,
        model: str,
        provider: str,
        language: str | None = None,
        duration: float | None = None,
        segments: list[dict] | None = None,
        raw_response: Any = None
    ):
        self.text = text
        self.model = model
        self.provider = provider
        self.language = language
        self.duration = duration
        self.segments = segments
        self.raw_response = raw_response


class STTProvider:
    """
    Abstract base class for STT providers.

    All STT provider implementations must inherit from this class and implement
    the transcribe method.
    """

    def __init__(self, api_key: str | None = None, **kwargs):
        """
        Initialize the provider with an API key and optional configuration.

        Args:
            api_key (str | None): The API key for authentication.
            **kwargs: Additional provider-specific configuration parameters.
        """
        self.api_key = api_key

    @classmethod
    def list_models(cls, api_key: str | None = None, **kwargs) -> list[str]:
        """
        Standard interface for listing available STT models.

        Args:
            api_key (str | None): API key if needed for listing models
            **kwargs: Additional provider-specific parameters

        Returns:
            list[str]: List of available model names
        """
        return []

    async def _get_async_client(self) -> httpx.AsyncClient:
        """Get or create the internal httpx.AsyncClient."""
        if not hasattr(self, '_async_client') or self._async_client is None or self._async_client.is_closed:
            self._async_client = httpx.AsyncClient(timeout=300.0)
        return self._async_client

    async def aclose(self):
        """Close the internal httpx.AsyncClient if it exists."""
        if hasattr(self, '_async_client') and self._async_client and not self._async_client.is_closed:
            await self._async_client.aclose()

    def transcribe(
        self,
        request: STTRequest,
        **provider_specific_kwargs
    ) -> STTResponse:
        """
        Transcribe audio to text.
        """
        async def run_and_close():
            try:
                return await self.atranscribe(request, **provider_specific_kwargs)
            finally:
                await self.aclose()
        
        return asyncio.run(run_and_close())

    async def atranscribe(
        self,
        request: STTRequest,
        **provider_specific_kwargs
    ) -> STTResponse:
        """
        Transcribe audio to text asynchronously.

        Args:
            request (STTRequest): The request to make.
            **provider_specific_kwargs: Additional provider-specific parameters.

        Returns:
            STTResponse: The STT response with transcribed text.

        Raises:
            Exception: If the request fails.
        """
        raise NotImplementedError(
            "STT providers must implement the atranscribe method")
